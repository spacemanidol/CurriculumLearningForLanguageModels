Found 1 shards at wikitext-2/wiki.train.tokens.pos_sort
146778 sentences loaded
Data loaded into memory
Found 1 shards at wikitext-2/wiki.train.tokens.pos_sort
146778 sentences loaded
Data loaded into memory
USING SKIP CONNECTIONS
USING SKIP CONNECTIONS
USING SKIP CONNECTIONS
[['global_step:0', TensorShape([])],
 ['lm/CNN/W_cnn_0:0',
  TensorShape([Dimension(1), Dimension(1), Dimension(16), Dimension(32)])],
 ['lm/CNN/W_cnn_1:0',
  TensorShape([Dimension(1), Dimension(2), Dimension(16), Dimension(32)])],
 ['lm/CNN/W_cnn_2:0',
  TensorShape([Dimension(1), Dimension(3), Dimension(16), Dimension(64)])],
 ['lm/CNN/W_cnn_3:0',
  TensorShape([Dimension(1), Dimension(4), Dimension(16), Dimension(128)])],
 ['lm/CNN/W_cnn_4:0',
  TensorShape([Dimension(1), Dimension(5), Dimension(16), Dimension(256)])],
 ['lm/CNN/W_cnn_5:0',
  TensorShape([Dimension(1), Dimension(6), Dimension(16), Dimension(512)])],
 ['lm/CNN/W_cnn_6:0',
  TensorShape([Dimension(1), Dimension(7), Dimension(16), Dimension(1024)])],
 ['lm/CNN/b_cnn_0:0', TensorShape([Dimension(32)])],
 ['lm/CNN/b_cnn_1:0', TensorShape([Dimension(32)])],
 ['lm/CNN/b_cnn_2:0', TensorShape([Dimension(64)])],
 ['lm/CNN/b_cnn_3:0', TensorShape([Dimension(128)])],
 ['lm/CNN/b_cnn_4:0', TensorShape([Dimension(256)])],
 ['lm/CNN/b_cnn_5:0', TensorShape([Dimension(512)])],
 ['lm/CNN/b_cnn_6:0', TensorShape([Dimension(1024)])],
 ['lm/CNN_high_0/W_carry:0', TensorShape([Dimension(2048), Dimension(2048)])],
 ['lm/CNN_high_0/W_transform:0',
  TensorShape([Dimension(2048), Dimension(2048)])],
 ['lm/CNN_high_0/b_carry:0', TensorShape([Dimension(2048)])],
 ['lm/CNN_high_0/b_transform:0', TensorShape([Dimension(2048)])],
 ['lm/CNN_high_1/W_carry:0', TensorShape([Dimension(2048), Dimension(2048)])],
 ['lm/CNN_high_1/W_transform:0',
  TensorShape([Dimension(2048), Dimension(2048)])],
 ['lm/CNN_high_1/b_carry:0', TensorShape([Dimension(2048)])],
 ['lm/CNN_high_1/b_transform:0', TensorShape([Dimension(2048)])],
 ['lm/CNN_proj/W_proj:0', TensorShape([Dimension(2048), Dimension(512)])],
 ['lm/CNN_proj/b_proj:0', TensorShape([Dimension(512)])],
 ['lm/RNN_0/rnn/multi_rnn_cell/cell_0/lstm_cell/bias:0',
  TensorShape([Dimension(16384)])],
 ['lm/RNN_0/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel:0',
  TensorShape([Dimension(1024), Dimension(16384)])],
 ['lm/RNN_0/rnn/multi_rnn_cell/cell_0/lstm_cell/projection/kernel:0',
  TensorShape([Dimension(4096), Dimension(512)])],
 ['lm/RNN_0/rnn/multi_rnn_cell/cell_1/lstm_cell/bias:0',
  TensorShape([Dimension(16384)])],
 ['lm/RNN_0/rnn/multi_rnn_cell/cell_1/lstm_cell/kernel:0',
  TensorShape([Dimension(1024), Dimension(16384)])],
 ['lm/RNN_0/rnn/multi_rnn_cell/cell_1/lstm_cell/projection/kernel:0',
  TensorShape([Dimension(4096), Dimension(512)])],
 ['lm/RNN_1/rnn/multi_rnn_cell/cell_0/lstm_cell/bias:0',
  TensorShape([Dimension(16384)])],
 ['lm/RNN_1/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel:0',
  TensorShape([Dimension(1024), Dimension(16384)])],
 ['lm/RNN_1/rnn/multi_rnn_cell/cell_0/lstm_cell/projection/kernel:0',
  TensorShape([Dimension(4096), Dimension(512)])],
 ['lm/RNN_1/rnn/multi_rnn_cell/cell_1/lstm_cell/bias:0',
  TensorShape([Dimension(16384)])],
 ['lm/RNN_1/rnn/multi_rnn_cell/cell_1/lstm_cell/kernel:0',
  TensorShape([Dimension(1024), Dimension(16384)])],
 ['lm/RNN_1/rnn/multi_rnn_cell/cell_1/lstm_cell/projection/kernel:0',
  TensorShape([Dimension(4096), Dimension(512)])],
 ['lm/char_embed:0', TensorShape([Dimension(261), Dimension(16)])],
 ['lm/softmax/W:0', TensorShape([Dimension(33155), Dimension(512)])],
 ['lm/softmax/b:0', TensorShape([Dimension(33155)])],
 ['train_perplexity:0', TensorShape([])]]
Training for 10 epochs and 3823 batches
is Char input:True
Training model with curriculum. Starting competence:0.1. 
 Competence increment 0.0004
Batch 1, train_perplexity=30364.998
Batch 5, train_perplexity=606.4422
Batch 10, train_perplexity=35403.316
Batch 15, train_perplexity=109.087425
Batch 20, train_perplexity=4238.0684
Batch 25, train_perplexity=353.99936
Batch 30, train_perplexity=66.95291
Batch 35, train_perplexity=127.5534
Batch 40, train_perplexity=103.35161
Batch 45, train_perplexity=47.088646
Batch 50, train_perplexity=42.978542
Batch 55, train_perplexity=35.30229
Batch 60, train_perplexity=36.081264
Batch 65, train_perplexity=91.77098
Batch 70, train_perplexity=35.53796
Batch 75, train_perplexity=47.315525
Batch 80, train_perplexity=244.9407
Batch 85, train_perplexity=35.15587
Batch 90, train_perplexity=40.961708
Batch 95, train_perplexity=87.09471
Batch 100, train_perplexity=33.219448
Batch 105, train_perplexity=34.636147
Batch 110, train_perplexity=36.797077
Batch 115, train_perplexity=55.103012
Batch 120, train_perplexity=35.13844
Batch 125, train_perplexity=46.141632
Batch 130, train_perplexity=28.891573
Batch 135, train_perplexity=45.65061
Batch 140, train_perplexity=29.621578
Batch 145, train_perplexity=38.923862
Batch 150, train_perplexity=39.760605
Batch 155, train_perplexity=32.20536
Batch 160, train_perplexity=39.052586
Batch 165, train_perplexity=32.65254
Batch 170, train_perplexity=42.319332
Batch 175, train_perplexity=30.617245
Batch 180, train_perplexity=36.412655
Batch 185, train_perplexity=35.60472
Batch 190, train_perplexity=34.724632
Batch 195, train_perplexity=43.81925
Batch 200, train_perplexity=35.48147
Batch 205, train_perplexity=31.968103
Batch 210, train_perplexity=38.059906
Batch 215, train_perplexity=31.696268
Batch 220, train_perplexity=39.15906
Batch 225, train_perplexity=34.31993
Batch 230, train_perplexity=31.7946
Batch 235, train_perplexity=44.606133
Batch 240, train_perplexity=37.252388
Batch 245, train_perplexity=37.980335
Batch 250, train_perplexity=42.949387
Batch 255, train_perplexity=35.03702
Batch 260, train_perplexity=42.82162
Batch 265, train_perplexity=43.747585
Batch 270, train_perplexity=38.840893
Batch 275, train_perplexity=42.70811
Batch 280, train_perplexity=36.652668
Batch 285, train_perplexity=40.260044
Batch 290, train_perplexity=36.88778
Batch 295, train_perplexity=42.047073
Batch 300, train_perplexity=40.6035
Batch 305, train_perplexity=43.20437
Batch 310, train_perplexity=44.748653
Batch 315, train_perplexity=32.933014
Batch 320, train_perplexity=42.694374
Batch 325, train_perplexity=43.203907
Batch 330, train_perplexity=37.95203
Batch 335, train_perplexity=44.94336
Batch 340, train_perplexity=35.822693
Batch 345, train_perplexity=38.935463
Batch 350, train_perplexity=44.21338
Batch 355, train_perplexity=43.55181
Batch 360, train_perplexity=47.019722
Batch 365, train_perplexity=42.07969
Batch 370, train_perplexity=42.54266
Batch 375, train_perplexity=40.80493
Batch 380, train_perplexity=41.69703
Batch 385, train_perplexity=39.14883
Batch 390, train_perplexity=39.297455
Batch 395, train_perplexity=36.694008
Batch 400, train_perplexity=42.045128
Batch 405, train_perplexity=44.820377
Batch 410, train_perplexity=44.741528
Batch 415, train_perplexity=40.74637
Batch 420, train_perplexity=42.36638
Batch 425, train_perplexity=41.096386
Batch 430, train_perplexity=36.215538
Batch 435, train_perplexity=49.45479
Batch 440, train_perplexity=43.05378
Batch 445, train_perplexity=50.463417
Batch 450, train_perplexity=46.420055
Batch 455, train_perplexity=45.98476
Batch 460, train_perplexity=39.02027
Batch 465, train_perplexity=57.575176
Batch 470, train_perplexity=48.133064
Batch 475, train_perplexity=46.986774
Batch 480, train_perplexity=39.799946
Batch 485, train_perplexity=44.32695
Batch 490, train_perplexity=43.47216
Batch 495, train_perplexity=48.964714
Batch 500, train_perplexity=49.150837
Batch 505, train_perplexity=46.64699
Batch 510, train_perplexity=44.506752
Batch 515, train_perplexity=42.92002
Batch 520, train_perplexity=48.974487
Batch 525, train_perplexity=43.183853
Batch 530, train_perplexity=50.340115
Batch 535, train_perplexity=46.076824
Batch 540, train_perplexity=41.62955
Batch 545, train_perplexity=45.75895
Batch 550, train_perplexity=41.568775
Batch 555, train_perplexity=41.44281
Batch 560, train_perplexity=46.78592
Batch 565, train_perplexity=42.797592
Batch 570, train_perplexity=52.077316
Batch 575, train_perplexity=41.291656
Batch 580, train_perplexity=48.102043
Batch 585, train_perplexity=50.726894