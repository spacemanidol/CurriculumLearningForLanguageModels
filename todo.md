Things to do Progressive
Train and Eval Perplexity Enwiki103
Train and Eval Perplexity wiki2
Downstream on Glue
Eval enWiki103 and wiki2 on public benchmark elmo models
Subsampling pipelines
1. Length
2. Sentence Parse(Depth)
3. Random
4. Subsample based on perplexity/entropy of text
5. Completeness?



1. Writting backgroung on 
Language Representations
-Word2Vec
-Glove
Transformers and Neural Architetures
-Attention is All you need
-Transformer XL
-LSTMs
-Simple LSTM
Neural Language Models
-BERT
-ELMO(Focus)
-ELECTRA
-GPT-2
-CoVe
-ALBERT
-Roberta
-DISTILBERT
Curriculum learning
-Curriculum learning Basica
-Curriculum learning in Neural Machine Translation

Progressive and Sampling learning
-Progressive Training of GANs
-







